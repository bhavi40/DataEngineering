# ğŸš€ YouTube Trending Data ETL Pipeline (AWS)
Understanding what makes a YouTube video go viral

## ğŸ“Œ Project Overview
This project analyzes YouTube trending video data collected using an end-to-end AWS ETL pipeline.
The goal is to identify key factors that influence the popularity of YouTube videos and present insights through a Tableau dashboard.

---

## Architecture Flow
![ETL Architecture Flow](https://github.com/bhavi40/DataEngineering/blob/main/Youtube%20Analytics/Architecture.png)

## Workflow Steps
Used the following AWS services:
  - **AWS CLI** - To push the raw data to S3
  - **Amazon S3** - Raw & Processed data storage
  - **AWS Step Functions** - Workflow orchestration
  - **Amazon Lambda** - clean the Json and convert into parquet
  - **AWS Glue ETL Job** - Transform raw csv files into optimized parquet
  - **AWS Glue Crawler** - Auto-detect files in s3 â†’ catalog tables
  - **AWS Glue Catalog** - Metadata storage for Athena
  - **Amazon Athena** - SQL queries directly on S3
  - **AWS Glue ETL Job** - To Join the cleaned csv and Json 
---

## 2. DataSet
- Data is  sourced from kaggle - ![Kaggle Data](https://www.kaggle.com/datasets/datasnaek/youtube-new)
---


## ğŸ“ Project Structure
```text
ğŸ“¦ AWS-ETL-Pipeline
â”‚
â”œâ”€â”€ S3_cli_command.sh
â”‚   â”œâ”€â”€ [Scripts to send local data to s3]
â”‚
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ [Kaggle Link]
â”‚
â”œâ”€â”€ Lambda_function_cleanJson.py
â”‚   â”œâ”€â”€ python code to clean JSON and convert into optimized parquet files and store them in s3
â”‚
â”œâ”€â”€ ETL JOB-cleansed-csv-to-parquet.py
â”‚   â”œâ”€â”€ python code that imports data from data catalog and converts into optimized parquet file
â”‚
â”œâ”€â”€ ETL JOB- joining-csv-json.py
â”‚   â”œâ”€â”€ python code that imports csv and json tables from data catalog,  joins them and converts to optimized parquet file
â”‚
â””â”€â”€ README.md
```
---

## Installations

AWS CLI - ![Guide to Install AWS CLI](https://aws.amazon.com/cli/)

