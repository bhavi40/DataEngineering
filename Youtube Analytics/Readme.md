# ğŸš€ YouTube Trending Data ETL Pipeline (AWS)
Understanding what makes a YouTube video go viral

## ğŸ“Œ Project Overview
This project analyzes YouTube trending video data collected using an end-to-end AWS ETL pipeline.
The goal is to identify key factors that influence the popularity of YouTube videos and present insights through a Tableau dashboard.

---

## Architecture Flow
![ETL Architecture Flow](https://github.com/bhavi40/DataEngineering/blob/main/Youtube%20Analytics/AWS%20Data%20Pipeline%20%20Architecture.png)

## 1. Workflow Steps
Used the following AWS services:
  - **Amazon S3** - Raw & Processed data storage
  - **AWS Glue Crawler** - Auto-detect files in s3 â†’ catalog tables
  - **AWS Glue ETL Job** - Transform raw csv files into optimized Parquet
  - **AWS Glue Catalog** - Metadata storage for Athena
  - **Amazon Athena** - SQL queries directly on S3
  - **AWS Step Functions** - Workflow orchestration
---

## 2. DataSet
- Data sourced from:
   - GitHub â€“ eCommerce dataset (CSV files)
   - Azure SQL â€“ product and sales data
- Used Azure Data Factory (ADF) pipelines to ingest data from both sources into ADLS Gen2 (Bronze layer).
---

## 3. Data Transformation (Silver Layer)
- Transformation done in Azure Databricks using PySpark:
   - Data cleaning, deduplication, and formatting
   - Joins and enrichment with data from Azure Cosmos DB
   - Creation of derived columns
- Transformed data stored back in ADLS Gen2 â†’ Silver layer
---

## Data Serving (Gold Layer)
- Connected Azure Synapse Analytics to the ADLS Gen2 Silver layer.
- Created views and external tables in Synapse for the Gold layer.
- Final curated data is ready for dashboards and analytical queries.
---

## ğŸ“ Project Structure
```text
ğŸ“¦ Azure-ETL-Pipeline
â”‚
â”œâ”€â”€ CodeForDataIngestion/
â”‚   â”œâ”€â”€ [Scripts to send local data to Azure SQL & Cosmos DB]
â”‚   â””â”€â”€ (Acts as data source for ADF pipelines)
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ [GitHub-based source data files, e.g., ecommerce CSVs]
â”‚   â””â”€â”€ (Raw data for ingestion to ADLS Gen2 Bronze layer)
â”‚
â”œâ”€â”€ Databricks_ecommerce.ipynb
â”‚   â”œâ”€â”€ PySpark transformation logic:
â”‚   â”‚   - Cleans and enriches data
â”‚   â”‚   - Joins with Cosmos DB
â”‚   â”‚   - Writes to Silver layer in ADLS Gen2
â”‚
â”œâ”€â”€ ForEachInput.json
â”‚   â”œâ”€â”€ ADF helper file for lookup activity:
â”‚   â”‚   - Used to iterate through multiple input files dynamically
â”‚   â”‚   - Enables sequential ingestion without manual uploads
â”‚
â”œâ”€â”€ ForEachInputScript.ipynb
â”‚   â”œâ”€â”€ Python/Notebook used to generate the `ForEachInput.json` dynamically
â”‚   â”‚   - Simplifies automation of the pipelineâ€™s lookup step
â”‚
â””â”€â”€ README.md



